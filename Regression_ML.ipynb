{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59414d6a",
   "metadata": {},
   "source": [
    "# Regression ML Assignment - Q&A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850f10a7",
   "metadata": {},
   "source": [
    "**Q: What is Simple Linear Regression**\n",
    "\n",
    "A: Simple Linear Regression is a statistical method that allows us to summarize and study relationships between two continuous (quantitative) variables. One variable, denoted X, is regarded as the predictor or independent variable. The other variable, Y, is regarded as the response or dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c38c9",
   "metadata": {},
   "source": [
    "**Q: What are the key assumptions of Simple Linear Regression**\n",
    "\n",
    "A: 1. Linearity: The relationship between the independent and dependent variable is linear.\n",
    "2. Independence: Observations are independent of each other.\n",
    "3. Homoscedasticity: Constant variance of residuals.\n",
    "4. Normality: Residuals of the model are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5bbd0f",
   "metadata": {},
   "source": [
    "**Q: What does the coefficient m represent in the equation Y=mX+c**\n",
    "\n",
    "A: The coefficient m represents the slope of the regression line, indicating the change in the dependent variable Y for a one-unit change in the independent variable X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a441641",
   "metadata": {},
   "source": [
    "**Q: What does the intercept c represent in the equation Y=mX+c**\n",
    "\n",
    "A: The intercept c is the value of Y when X is 0. It represents the point where the regression line crosses the Y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d73f4f",
   "metadata": {},
   "source": [
    "**Q: How do we calculate the slope m in Simple Linear Regression**\n",
    "\n",
    "A: The slope m is calculated as: m = Σ((X - mean(X)) * (Y - mean(Y))) / Σ((X - mean(X))²)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0d7582",
   "metadata": {},
   "source": [
    "**Q: What is the purpose of the least squares method in Simple Linear Regression**\n",
    "\n",
    "A: The least squares method minimizes the sum of the squares of the residuals (the differences between observed and predicted values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626332d3",
   "metadata": {},
   "source": [
    "**Q: How is the coefficient of determination (R²) interpreted in Simple Linear Regression**\n",
    "\n",
    "A: R² indicates the proportion of variance in the dependent variable that is predictable from the independent variable. A higher R² means a better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7898d3",
   "metadata": {},
   "source": [
    "**Q: What is Multiple Linear Regression**\n",
    "\n",
    "A: Multiple Linear Regression is an extension of Simple Linear Regression where more than one independent variable is used to predict the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9554b7",
   "metadata": {},
   "source": [
    "**Q: What is the main difference between Simple and Multiple Linear Regression**\n",
    "\n",
    "A: Simple Linear Regression uses one independent variable, while Multiple Linear Regression uses two or more independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe285e5f",
   "metadata": {},
   "source": [
    "**Q: What are the key assumptions of Multiple Linear Regression**\n",
    "\n",
    "A: 1. Linearity\n",
    "2. Independence\n",
    "3. Homoscedasticity\n",
    "4. Normality of residuals\n",
    "5. No multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a30831",
   "metadata": {},
   "source": [
    "**Q: What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model**\n",
    "\n",
    "A: Heteroscedasticity refers to non-constant variance of residuals. It violates regression assumptions and can lead to inefficient estimates and incorrect conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb38119",
   "metadata": {},
   "source": [
    "**Q: How can you improve a Multiple Linear Regression model with high multicollinearity**\n",
    "\n",
    "A: By removing highly correlated predictors, using PCA, or using regularization techniques like Ridge or Lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0653ca",
   "metadata": {},
   "source": [
    "**Q: What are some common techniques for transforming categorical variables for use in regression models**\n",
    "\n",
    "A: Label Encoding, One-Hot Encoding, and Dummy Variable encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c025dd4",
   "metadata": {},
   "source": [
    "**Q: What is the role of interaction terms in Multiple Linear Regression**\n",
    "\n",
    "A: Interaction terms capture the effect of two or more variables acting together on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01618682",
   "metadata": {},
   "source": [
    "**Q: How can the interpretation of intercept differ between Simple and Multiple Linear Regression**\n",
    "\n",
    "A: In Simple Linear Regression, it is the expected value of Y when X is 0. In Multiple Linear Regression, it is the expected Y when all predictors are 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec6029f",
   "metadata": {},
   "source": [
    "**Q: What is the significance of the slope in regression analysis, and how does it affect predictions**\n",
    "\n",
    "A: The slope indicates the direction and magnitude of the relationship between independent and dependent variables. It directly affects predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603f225",
   "metadata": {},
   "source": [
    "**Q: How does the intercept in a regression model provide context for the relationship between variables**\n",
    "\n",
    "A: The intercept provides a baseline value of the dependent variable when all independent variables are zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752cbc2",
   "metadata": {},
   "source": [
    "**Q: What are the limitations of using R² as a sole measure of model performance**\n",
    "\n",
    "A: R² does not indicate whether the regression model is adequate. It can be artificially high and doesn’t reflect overfitting or predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900fc55f",
   "metadata": {},
   "source": [
    "**Q: How would you interpret a large standard error for a regression coefficient**\n",
    "\n",
    "A: A large standard error suggests that the coefficient estimate is not precise and may not be statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a71de1",
   "metadata": {},
   "source": [
    "**Q: How can heteroscedasticity be identified in residual plots, and why is it important to address it**\n",
    "\n",
    "A: It appears as a funnel shape in residual plots. It's important to address it because it violates model assumptions and can bias standard errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f42f0",
   "metadata": {},
   "source": [
    "**Q: What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²**\n",
    "\n",
    "A: It suggests that not all added predictors are contributing meaningfully, and some may be causing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8221785",
   "metadata": {},
   "source": [
    "**Q: Why is it important to scale variables in Multiple Linear Regression**\n",
    "\n",
    "A: To ensure that coefficients are comparable and to improve numerical stability and model convergence, especially for regularization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d31ce4",
   "metadata": {},
   "source": [
    "**Q: What is polynomial regression**\n",
    "\n",
    "A: Polynomial Regression is a form of regression analysis where the relationship between the independent variable and dependent variable is modeled as an nth degree polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533e738",
   "metadata": {},
   "source": [
    "**Q: How does polynomial regression differ from linear regression**\n",
    "\n",
    "A: Linear regression fits a straight line while polynomial regression fits a curved line by including higher-degree terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ec51a0",
   "metadata": {},
   "source": [
    "**Q: When is polynomial regression used**\n",
    "\n",
    "A: When the data shows a curvilinear relationship between the independent and dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f311d51b",
   "metadata": {},
   "source": [
    "**Q: What is the general equation for polynomial regression**\n",
    "\n",
    "A: Y = β₀ + β₁X + β₂X² + ... + βₙXⁿ + ε"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ab669",
   "metadata": {},
   "source": [
    "**Q: Can polynomial regression be applied to multiple variables**\n",
    "\n",
    "A: Yes, it can be extended to multiple variables by including polynomial terms of each variable and their interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d271f13",
   "metadata": {},
   "source": [
    "**Q: What are the limitations of polynomial regression**\n",
    "\n",
    "A: 1. Overfitting with high-degree polynomials\n",
    "2. Poor extrapolation\n",
    "3. Computational complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98955975",
   "metadata": {},
   "source": [
    "**Q: What methods can be used to evaluate model fit when selecting the degree of a polynomial**\n",
    "\n",
    "A: Cross-validation, Adjusted R², AIC, BIC, and residual plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716781d",
   "metadata": {},
   "source": [
    "**Q: Why is visualization important in polynomial regression**\n",
    "\n",
    "A: Visualization helps in understanding the fit of the model and in detecting overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac67a37",
   "metadata": {},
   "source": [
    "**Q: How is polynomial regression implemented in Python?**\n",
    "\n",
    "A: Using `numpy.polyfit`, `PolynomialFeatures` from `sklearn.preprocessing`, and fitting with `LinearRegression`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
